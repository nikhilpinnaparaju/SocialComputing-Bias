{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import preprocessor as p\n",
    "import numpy as np\n",
    "import pandas\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    p.set_options(p.OPT.URL,p.OPT.MENTION,p.OPT.EMOJI,p.OPT.HASHTAG)\n",
    "    return p.tokenize(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24778</td>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24779</td>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24780</td>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24781</td>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24782</td>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('../HS_labeled_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI ,p.OPT.HASHTAG)\n",
    "    return p.tokenize(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer(split_text):\n",
    "    sent2idx = []\n",
    "    for w in split_text:\n",
    "        if w.lower() in word2idx:\n",
    "            sent2idx.append(word2idx[w.lower()])\n",
    "        else:\n",
    "            sent2idx.append(word2idx['_UNK'])\n",
    "            \n",
    "    return sent2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8997</td>\n",
       "      <td>9246</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Everybody @CollinFlemons was bout to fuck a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15628</td>\n",
       "      <td>15994</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @ImNeverChillin: You get drunk with a bitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7574</td>\n",
       "      <td>7788</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>All I wants is to represent da life o da color...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13481</td>\n",
       "      <td>13812</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Now all the hoes bout to post \"the saints lost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16851</td>\n",
       "      <td>17236</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @PRAYINGFORHEAD: ya pussy stank @_ANGELSAMU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23177</td>\n",
       "      <td>23661</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yo bitch choosin just let her http://t.co/zg6X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18701</td>\n",
       "      <td>19116</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @bugattibeez: \"Nicki Minaj ass so fake.\" -a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18638</td>\n",
       "      <td>19050</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @beauty_briii: One of my classmates offered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14120</td>\n",
       "      <td>14460</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Adrian1_knowsu: @0124jessi lml se pasa de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2123</td>\n",
       "      <td>2166</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>' You niggahs actin like hoes , I can sale tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18587 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "8997         9246      3            1                   2        0      1   \n",
       "15628       15994      3            0                   3        0      1   \n",
       "7574         7788      3            0                   0        3      2   \n",
       "13481       13812      3            0                   2        1      1   \n",
       "16851       17236      4            0                   4        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "23177       23661      6            0                   6        0      1   \n",
       "18701       19116      3            0                   3        0      1   \n",
       "18638       19050      3            0                   0        3      2   \n",
       "14120       14460      3            0                   3        0      1   \n",
       "2123         2166      3            0                   3        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "8997   Everybody @CollinFlemons was bout to fuck a fa...  \n",
       "15628  RT @ImNeverChillin: You get drunk with a bitch...  \n",
       "7574   All I wants is to represent da life o da color...  \n",
       "13481  Now all the hoes bout to post \"the saints lost...  \n",
       "16851  RT @PRAYINGFORHEAD: ya pussy stank @_ANGELSAMU...  \n",
       "...                                                  ...  \n",
       "23177  Yo bitch choosin just let her http://t.co/zg6X...  \n",
       "18701  RT @bugattibeez: \"Nicki Minaj ass so fake.\" -a...  \n",
       "18638  RT @beauty_briii: One of my classmates offered...  \n",
       "14120  RT @Adrian1_knowsu: @0124jessi lml se pasa de ...  \n",
       "2123   ' You niggahs actin like hoes , I can sale tho...  \n",
       "\n",
       "[18587 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "100%|██████████| 18587/18587 [00:00<00:00, 142178.37it/s]\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train['clean_text'] = train.tweet.apply(lambda x: preprocess(x.lower().strip()))\n",
    "\n",
    "words = Counter()\n",
    "for sent in tqdm(train.clean_text.values):\n",
    "    words.update(w.lower() for w in sent)\n",
    "   \n",
    "# sort with most frequently occuring words first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# add <pad> and <unk> token to vocab which will be used later\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "train['sentence2idx'] = train.clean_text.apply(lambda x: indexer(x))\n",
    "train['length'] = train.clean_text.apply(lambda x: len(x))\n",
    "train['label'] = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.plot(train.length.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "valid['clean_text'] = valid.tweet.apply(lambda x: preprocess(x.strip()))\n",
    "\n",
    "valid['sentence2idx'] = valid.clean_text.apply(lambda x: indexer(x))\n",
    "valid['length'] = valid.clean_text.apply(lambda x: len(x))\n",
    "valid['label'] = valid['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df, maxlen=30):\n",
    "        self.maxlen = maxlen\n",
    "        self.df = df\n",
    "#         print('Padding')\n",
    "        self.df['padded_text'] = self.df.sentence2idx.apply(lambda x: self.pad_data(x))\n",
    "        self.padded_text = list(self.df.padded_text)\n",
    "        self.labels = list(self.df.label)\n",
    "        self.lengths = list(self.df.length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         lens = self.df.length[idx]\n",
    "        X = self.padded_text[idx]\n",
    "        y = self.labels[idx]\n",
    "        lens = self.lengths[idx]\n",
    "        return X,y,lens\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_loader = VectorizeData(train)\n",
    "valid_loader = VectorizeData(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "tl = DataLoader(dataset=train_loader, batch_size=100, shuffle=True)\n",
    "print(len(tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "vl = DataLoader(dataset=valid_loader, batch_size=100, shuffle=False)\n",
    "print(len(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[    7,   204, 10983,  ...,     0,     0,     0],\n",
      "        [   32,  6887,   232,  ...,     0,     0,     0],\n",
      "        [  632, 25087, 25088,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   39,    30,   403,  ...,     0,     0,     0],\n",
      "        [    9,    47,    43,  ...,     0,     0,     0],\n",
      "        [    2,  1056,  5538,  ...,     0,     0,     0]]), tensor([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2,\n",
      "        1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2,\n",
      "        1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1]), tensor([11,  7,  5, 15,  8, 18,  7, 16,  6, 13, 10,  3, 20, 10, 10,  6, 14, 21,\n",
      "        18, 13, 14, 20, 18,  7, 10, 10, 23, 13, 18, 14, 10, 24, 19, 12, 18, 17,\n",
      "         3, 23, 17,  9, 11, 11,  7,  2, 21,  9, 17, 25, 19,  9, 18, 18, 11, 20,\n",
      "        18, 16, 26,  8, 16,  7,  4, 27,  5, 18,  6, 22,  9, 17, 19, 25, 21, 21,\n",
      "         6, 10,  3, 18, 15, 20, 20, 13,  8, 11, 21, 22, 14, 23, 12,  5, 16, 24,\n",
      "        22, 20, 10, 11, 21, 10, 12, 21, 22,  5])]\n"
     ]
    }
   ],
   "source": [
    "for i, samples in enumerate(tl):\n",
    "    print(i)\n",
    "    print(samples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[  2,   5, 105,  ...,   0,   0,   0],\n",
      "        [529,  25,   8,  ...,   0,   0,   0],\n",
      "        [118, 516,   0,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [165,   5, 106,  ...,   0,   0,   0],\n",
      "        [  4,   6,  98,  ...,   0,   0,   0],\n",
      "        [  2, 282,   9,  ...,   0,   0,   0]]), tensor([2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
      "        1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
      "        1, 2, 1, 1]), tensor([13,  7,  2, 13, 12, 22, 14,  4, 18,  4,  9, 12,  8,  6,  9, 18,  7, 13,\n",
      "         7,  4, 17, 25, 12, 22, 15, 14, 19, 17,  9, 21, 12, 17, 19, 13,  4,  6,\n",
      "         8, 27, 19, 26,  4, 10,  4,  8, 17,  9, 28, 19, 24,  9,  5, 19, 22,  6,\n",
      "        16, 11, 11, 13, 10, 20, 20, 17, 20, 16, 12,  9, 17, 10, 20, 18, 26, 28,\n",
      "        26, 15, 10,  9, 10,  7,  5, 23, 16, 23, 28, 16, 14, 20, 11,  4, 13, 23,\n",
      "        15, 14,  5, 14, 27,  7, 25,  7, 23, 24])]\n"
     ]
    }
   ],
   "source": [
    "for i, samples in enumerate(vl):\n",
    "    print(i)\n",
    "    print(samples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecAttnArch(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, bidir, rnnType, attnType,device):\n",
    "        super(RecAttnArch, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.rnnType = rnnType\n",
    "        self.attnType = attnType\n",
    "        self.bidirectional = bidir\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.numDirs = 2\n",
    "        else:\n",
    "            self.numDirs = 1\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, embedding_dim)\n",
    "        \n",
    "        if self.rnnType == 'lstm':\n",
    "            self.recNN = nn.LSTM(embedding_dim,hidden_dim, num_layers,batch_first=True,bidirectional=self.bidirectional)\n",
    "            \n",
    "        if self.rnnType == 'gru':\n",
    "            self.recNN = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True,bidirectional=self.bidirectional)\n",
    "            \n",
    "        if self.rnnType == 'rnn':\n",
    "            self.recNN = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True, nonlinearity='tanh',bidirectional=self.bidirectional)\n",
    "        \n",
    "        self.query_vector = nn.Parameter(torch.rand(hidden_dim*self.numDirs,1)).float()\n",
    "        \n",
    "        self.attnWgtMatrixSize = [self.numDirs*self.hidden_dim, self.numDirs*self.hidden_dim]\n",
    "        self.attnWgtMatrix = nn.Parameter(torch.randn(self.attnWgtMatrixSize).float()) # Multiplicative Attention\n",
    "    \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        if self.attnType == 'dot':\n",
    "            self.fc = nn.Linear(self.numDirs*self.hidden_dim, output_dim)\n",
    "        \n",
    "        if self.attnType == 'self':\n",
    "            self.fc = nn.Linear(self.numDirs*30*self.hidden_dim, output_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self,x,encMode=False):\n",
    "        embs = self.emb(x)\n",
    "        embs = embs.view(x.size(0),-1,self.embedding_dim).to(self.device)\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "        \n",
    "        if self.rnnType == 'lstm':        \n",
    "            c0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "            \n",
    "            out,(hn,cn) = self.recNN(embs,(h0,c0))\n",
    "        \n",
    "        else:\n",
    "            out, hn = self.recNN(embs, h0)\n",
    "        \n",
    "        if self.attnType == 'dot':\n",
    "            Hw = out\n",
    "            attn_weights = self.softmax(Hw.matmul(self.query_vector))\n",
    "\n",
    "            out = out.mul(attn_weights)\n",
    "            context_vector = torch.sum(out,dim=1)\n",
    "            \n",
    "            fc_out = context_vector\n",
    "            \n",
    "        if self.attnType == 'self':\n",
    "            queryMatrix = out\n",
    "            keyMatrix = out.permute(0,2,1)\n",
    "            \n",
    "            attnScores = torch.bmm( torch.matmul(queryMatrix,self.attnWgtMatrix), keyMatrix )\n",
    "            attnScores = F.softmax(attnScores, dim=2)\n",
    "            hidden_matrix = torch.bmm(attnScores, queryMatrix)\n",
    "            \n",
    "            fc_out = hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2])\n",
    "        \n",
    "        if encMode:\n",
    "            return fc_out\n",
    "            \n",
    "        else:\n",
    "            return self.fc(fc_out)\n",
    "        \n",
    "    \n",
    "    def getScores(self,x):\n",
    "        embs = self.emb(x)\n",
    "        embs = embs.view(x.size(0),-1,self.embedding_dim).to(self.device)\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "        \n",
    "        if self.rnnType == 'lstm':        \n",
    "            c0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "            \n",
    "            out,(hn,cn) = self.recNN(embs,(h0,c0))\n",
    "        \n",
    "        else:\n",
    "            out, hn = self.recNN(embs, h0)\n",
    "        \n",
    "        if self.attnType == 'dot':\n",
    "            Hw = out\n",
    "            attn_weights = self.softmax(Hw.matmul(self.query_vector))\n",
    "            out = out.mul(attn_weights)\n",
    "            \n",
    "            return out\n",
    "            \n",
    "        if self.attnType == 'self':\n",
    "            queryMatrix = out\n",
    "            keyMatrix = out.permute(0,2,1)\n",
    "            \n",
    "            attnScores = torch.bmm( torch.matmul(queryMatrix,self.attnWgtMatrix), keyMatrix )\n",
    "            attnScores = F.softmax(attnScores, dim=2)\n",
    "            \n",
    "            return attnScores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal combination seems to be with GRU of 50 units and 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecAttnArch(\n",
       "  (emb): Embedding(27596, 256)\n",
       "  (recNN): GRU(256, 50, batch_first=True, bidirectional=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (fc): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 256\n",
    "n_hidden = 50\n",
    "n_out = 4\n",
    "num_layers = 1\n",
    "rnnType = 'gru'\n",
    "bidir = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:2'\n",
    "    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "model = model = RecAttnArch(vocab_size,embedding_dim,n_hidden,n_out,num_layers,bidir,rnnType,'dot',device)\n",
    "model.to(device)\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecAttnArch(\n",
       "  (emb): Embedding(27596, 256)\n",
       "  (recNN): GRU(256, 50, batch_first=True, bidirectional=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (fc): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "\n",
      "  0%|          | 1/200 [00:01<04:54,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.855067785668173 F1 0.40278311456726323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       346\n",
      "           1       0.88      0.96      0.92      4800\n",
      "           2       0.72      0.67      0.69      1050\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6196\n",
      "   macro avg       0.40      0.41      0.40      6196\n",
      "weighted avg       0.80      0.86      0.83      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/200 [00:02<04:35,  1.39s/it]\u001b[A\n",
      "  2%|▏         | 3/200 [00:03<04:20,  1.32s/it]\u001b[A\n",
      "  2%|▏         | 4/200 [00:04<04:10,  1.28s/it]\u001b[A\n",
      "  2%|▎         | 5/200 [00:06<04:02,  1.24s/it]\u001b[A\n",
      "  3%|▎         | 6/200 [00:07<03:56,  1.22s/it]\u001b[A\n",
      "  4%|▎         | 7/200 [00:08<03:52,  1.20s/it]\u001b[A\n",
      "  4%|▍         | 8/200 [00:09<03:48,  1.19s/it]\u001b[A\n",
      "  4%|▍         | 9/200 [00:10<03:45,  1.18s/it]\u001b[A\n",
      "  5%|▌         | 10/200 [00:11<03:43,  1.18s/it]\u001b[A\n",
      "  6%|▌         | 11/200 [00:13<03:41,  1.17s/it]\u001b[A\n",
      "  6%|▌         | 12/200 [00:14<03:39,  1.17s/it]\u001b[A\n",
      "  6%|▋         | 13/200 [00:15<03:38,  1.17s/it]\u001b[A\n",
      "  7%|▋         | 14/200 [00:16<03:36,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 15/200 [00:17<03:35,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 16/200 [00:18<03:34,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 17/200 [00:20<03:32,  1.16s/it]\u001b[A\n",
      "  9%|▉         | 18/200 [00:21<03:31,  1.16s/it]\u001b[A\n",
      " 10%|▉         | 19/200 [00:22<03:30,  1.16s/it]\u001b[A\n",
      " 10%|█         | 20/200 [00:23<03:29,  1.16s/it]\u001b[A\n",
      " 10%|█         | 21/200 [00:24<03:27,  1.16s/it]\u001b[A\n",
      " 11%|█         | 22/200 [00:25<03:26,  1.16s/it]\u001b[A\n",
      " 12%|█▏        | 23/200 [00:27<03:25,  1.16s/it]\u001b[A\n",
      " 12%|█▏        | 24/200 [00:28<03:24,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 25/200 [00:29<03:23,  1.16s/it]\u001b[A\n",
      " 13%|█▎        | 26/200 [00:30<03:22,  1.16s/it]\u001b[A\n",
      " 14%|█▎        | 27/200 [00:31<03:20,  1.16s/it]\u001b[A\n",
      " 14%|█▍        | 28/200 [00:32<03:19,  1.16s/it]\u001b[A\n",
      " 14%|█▍        | 29/200 [00:34<03:18,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 30/200 [00:35<03:17,  1.16s/it]\u001b[A\n",
      " 16%|█▌        | 31/200 [00:36<03:16,  1.16s/it]\u001b[A\n",
      " 16%|█▌        | 32/200 [00:37<03:15,  1.16s/it]\u001b[A\n",
      " 16%|█▋        | 33/200 [00:38<03:13,  1.16s/it]\u001b[A\n",
      " 17%|█▋        | 34/200 [00:39<03:12,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 35/200 [00:41<03:11,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 36/200 [00:42<03:12,  1.17s/it]\u001b[A\n",
      " 18%|█▊        | 37/200 [00:43<03:11,  1.17s/it]\u001b[A\n",
      " 19%|█▉        | 38/200 [00:44<03:10,  1.17s/it]\u001b[A\n",
      " 20%|█▉        | 39/200 [00:45<03:08,  1.17s/it]\u001b[A\n",
      " 20%|██        | 40/200 [00:46<03:07,  1.17s/it]\u001b[A\n",
      " 20%|██        | 41/200 [00:48<03:06,  1.17s/it]\u001b[A\n",
      " 21%|██        | 42/200 [00:49<03:05,  1.17s/it]\u001b[A\n",
      " 22%|██▏       | 43/200 [00:50<03:04,  1.17s/it]\u001b[A\n",
      " 22%|██▏       | 44/200 [00:51<03:02,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 45/200 [00:52<03:01,  1.17s/it]\u001b[A\n",
      " 23%|██▎       | 46/200 [00:53<03:00,  1.17s/it]\u001b[A\n",
      " 24%|██▎       | 47/200 [00:55<02:59,  1.17s/it]\u001b[A\n",
      " 24%|██▍       | 48/200 [00:56<02:58,  1.17s/it]\u001b[A\n",
      " 24%|██▍       | 49/200 [00:57<02:56,  1.17s/it]\u001b[A\n",
      " 25%|██▌       | 50/200 [00:58<02:55,  1.17s/it]\u001b[A\n",
      " 26%|██▌       | 51/200 [00:59<03:03,  1.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8248870238863784 F1 0.5713595972629173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.19      0.20       346\n",
      "           1       0.86      0.94      0.90      4800\n",
      "           2       0.80      0.49      0.61      1050\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6196\n",
      "   macro avg       0.63      0.54      0.57      6196\n",
      "weighted avg       0.82      0.82      0.81      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 52/200 [01:01<03:01,  1.22s/it]\u001b[A\n",
      " 26%|██▋       | 53/200 [01:02<02:57,  1.21s/it]\u001b[A\n",
      " 27%|██▋       | 54/200 [01:03<02:54,  1.19s/it]\u001b[A\n",
      " 28%|██▊       | 55/200 [01:04<02:51,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 56/200 [01:05<02:49,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 57/200 [01:07<02:47,  1.17s/it]\u001b[A\n",
      " 29%|██▉       | 58/200 [01:08<02:45,  1.17s/it]\u001b[A\n",
      " 30%|██▉       | 59/200 [01:09<02:44,  1.17s/it]\u001b[A\n",
      " 30%|███       | 60/200 [01:10<02:43,  1.17s/it]\u001b[A\n",
      " 30%|███       | 61/200 [01:11<02:41,  1.16s/it]\u001b[A\n",
      " 31%|███       | 62/200 [01:12<02:40,  1.16s/it]\u001b[A\n",
      " 32%|███▏      | 63/200 [01:13<02:39,  1.16s/it]\u001b[A\n",
      " 32%|███▏      | 64/200 [01:15<02:38,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 65/200 [01:16<02:36,  1.16s/it]\u001b[A\n",
      " 33%|███▎      | 66/200 [01:17<02:35,  1.16s/it]\u001b[A\n",
      " 34%|███▎      | 67/200 [01:18<02:34,  1.16s/it]\u001b[A\n",
      " 34%|███▍      | 68/200 [01:19<02:33,  1.16s/it]\u001b[A\n",
      " 34%|███▍      | 69/200 [01:20<02:32,  1.17s/it]\u001b[A\n",
      " 35%|███▌      | 70/200 [01:22<02:31,  1.17s/it]\u001b[A\n",
      " 36%|███▌      | 71/200 [01:23<02:30,  1.17s/it]\u001b[A\n",
      " 36%|███▌      | 72/200 [01:24<02:29,  1.17s/it]\u001b[A\n",
      " 36%|███▋      | 73/200 [01:25<02:28,  1.17s/it]\u001b[A\n",
      " 37%|███▋      | 74/200 [01:26<02:27,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 75/200 [01:27<02:26,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 76/200 [01:29<02:25,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 77/200 [01:30<02:23,  1.17s/it]\u001b[A\n",
      " 39%|███▉      | 78/200 [01:31<02:22,  1.17s/it]\u001b[A\n",
      " 40%|███▉      | 79/200 [01:32<02:21,  1.17s/it]\u001b[A\n",
      " 40%|████      | 80/200 [01:33<02:20,  1.17s/it]\u001b[A\n",
      " 40%|████      | 81/200 [01:35<02:19,  1.17s/it]\u001b[A\n",
      " 41%|████      | 82/200 [01:36<02:18,  1.17s/it]\u001b[A\n",
      " 42%|████▏     | 83/200 [01:37<02:16,  1.17s/it]\u001b[A\n",
      " 42%|████▏     | 84/200 [01:38<02:15,  1.17s/it]\u001b[A\n",
      " 42%|████▎     | 85/200 [01:39<02:14,  1.17s/it]\u001b[A\n",
      " 43%|████▎     | 86/200 [01:40<02:13,  1.17s/it]\u001b[A\n",
      " 44%|████▎     | 87/200 [01:42<02:12,  1.17s/it]\u001b[A\n",
      " 44%|████▍     | 88/200 [01:43<02:11,  1.17s/it]\u001b[A\n",
      " 44%|████▍     | 89/200 [01:44<02:09,  1.17s/it]\u001b[A\n",
      " 45%|████▌     | 90/200 [01:45<02:08,  1.17s/it]\u001b[A\n",
      " 46%|████▌     | 91/200 [01:46<02:08,  1.18s/it]\u001b[A\n",
      " 46%|████▌     | 92/200 [01:47<02:08,  1.19s/it]\u001b[A\n",
      " 46%|████▋     | 93/200 [01:49<02:06,  1.19s/it]\u001b[A\n",
      " 47%|████▋     | 94/200 [01:50<02:05,  1.18s/it]\u001b[A\n",
      " 48%|████▊     | 95/200 [01:51<02:03,  1.18s/it]\u001b[A\n",
      " 48%|████▊     | 96/200 [01:52<02:03,  1.19s/it]\u001b[A\n",
      " 48%|████▊     | 97/200 [01:53<02:01,  1.18s/it]\u001b[A\n",
      " 49%|████▉     | 98/200 [01:55<01:59,  1.17s/it]\u001b[A\n",
      " 50%|████▉     | 99/200 [01:56<01:58,  1.17s/it]\u001b[A\n",
      " 50%|█████     | 100/200 [01:57<01:56,  1.17s/it]\u001b[A\n",
      " 50%|█████     | 101/200 [01:58<02:00,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8240800516462233 F1 0.5710565070390707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.19      0.21       346\n",
      "           1       0.87      0.94      0.90      4800\n",
      "           2       0.78      0.50      0.61      1050\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6196\n",
      "   macro avg       0.62      0.54      0.57      6196\n",
      "weighted avg       0.81      0.82      0.81      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 102/200 [01:59<01:58,  1.21s/it]\u001b[A\n",
      " 52%|█████▏    | 103/200 [02:01<01:55,  1.19s/it]\u001b[A\n",
      " 52%|█████▏    | 104/200 [02:02<01:53,  1.18s/it]\u001b[A\n",
      " 52%|█████▎    | 105/200 [02:03<01:51,  1.18s/it]\u001b[A\n",
      " 53%|█████▎    | 106/200 [02:04<01:50,  1.18s/it]\u001b[A\n",
      " 54%|█████▎    | 107/200 [02:05<01:49,  1.17s/it]\u001b[A\n",
      " 54%|█████▍    | 108/200 [02:06<01:47,  1.17s/it]\u001b[A\n",
      " 55%|█████▍    | 109/200 [02:08<01:46,  1.17s/it]\u001b[A\n",
      " 55%|█████▌    | 110/200 [02:09<01:45,  1.17s/it]\u001b[A\n",
      " 56%|█████▌    | 111/200 [02:10<01:44,  1.17s/it]\u001b[A\n",
      " 56%|█████▌    | 112/200 [02:11<01:42,  1.17s/it]\u001b[A\n",
      " 56%|█████▋    | 113/200 [02:12<01:41,  1.17s/it]\u001b[A\n",
      " 57%|█████▋    | 114/200 [02:13<01:40,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 115/200 [02:15<01:39,  1.17s/it]\u001b[A\n",
      " 58%|█████▊    | 116/200 [02:16<01:38,  1.17s/it]\u001b[A\n",
      " 58%|█████▊    | 117/200 [02:17<01:37,  1.17s/it]\u001b[A\n",
      " 59%|█████▉    | 118/200 [02:18<01:36,  1.17s/it]\u001b[A\n",
      " 60%|█████▉    | 119/200 [02:19<01:34,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 120/200 [02:20<01:33,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 121/200 [02:22<01:32,  1.17s/it]\u001b[A\n",
      " 61%|██████    | 122/200 [02:23<01:31,  1.17s/it]\u001b[A\n",
      " 62%|██████▏   | 123/200 [02:24<01:30,  1.18s/it]\u001b[A\n",
      " 62%|██████▏   | 124/200 [02:25<01:29,  1.18s/it]\u001b[A\n",
      " 62%|██████▎   | 125/200 [02:26<01:28,  1.18s/it]\u001b[A\n",
      " 63%|██████▎   | 126/200 [02:27<01:26,  1.17s/it]\u001b[A\n",
      " 64%|██████▎   | 127/200 [02:29<01:25,  1.17s/it]\u001b[A\n",
      " 64%|██████▍   | 128/200 [02:30<01:24,  1.17s/it]\u001b[A\n",
      " 64%|██████▍   | 129/200 [02:31<01:23,  1.17s/it]\u001b[A\n",
      " 65%|██████▌   | 130/200 [02:32<01:21,  1.17s/it]\u001b[A\n",
      " 66%|██████▌   | 131/200 [02:33<01:20,  1.17s/it]\u001b[A\n",
      " 66%|██████▌   | 132/200 [02:34<01:19,  1.17s/it]\u001b[A\n",
      " 66%|██████▋   | 133/200 [02:36<01:18,  1.17s/it]\u001b[A\n",
      " 67%|██████▋   | 134/200 [02:37<01:17,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 135/200 [02:38<01:16,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 136/200 [02:39<01:14,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 137/200 [02:40<01:13,  1.17s/it]\u001b[A\n",
      " 69%|██████▉   | 138/200 [02:41<01:12,  1.17s/it]\u001b[A\n",
      " 70%|██████▉   | 139/200 [02:43<01:11,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 140/200 [02:44<01:10,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 141/200 [02:45<01:08,  1.17s/it]\u001b[A\n",
      " 71%|███████   | 142/200 [02:46<01:07,  1.17s/it]\u001b[A\n",
      " 72%|███████▏  | 143/200 [02:47<01:06,  1.17s/it]\u001b[A\n",
      " 72%|███████▏  | 144/200 [02:48<01:05,  1.17s/it]\u001b[A\n",
      " 72%|███████▎  | 145/200 [02:50<01:04,  1.17s/it]\u001b[A\n",
      " 73%|███████▎  | 146/200 [02:51<01:02,  1.17s/it]\u001b[A\n",
      " 74%|███████▎  | 147/200 [02:52<01:01,  1.17s/it]\u001b[A\n",
      " 74%|███████▍  | 148/200 [02:53<01:00,  1.17s/it]\u001b[A\n",
      " 74%|███████▍  | 149/200 [02:54<00:59,  1.17s/it]\u001b[A\n",
      " 75%|███████▌  | 150/200 [02:55<00:58,  1.17s/it]\u001b[A\n",
      " 76%|███████▌  | 151/200 [02:57<00:59,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8197224015493867 F1 0.5749323855364028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.23      0.23       346\n",
      "           1       0.87      0.94      0.90      4800\n",
      "           2       0.79      0.48      0.60      1050\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6196\n",
      "   macro avg       0.62      0.55      0.57      6196\n",
      "weighted avg       0.82      0.82      0.81      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 152/200 [02:58<00:58,  1.21s/it]\u001b[A\n",
      " 76%|███████▋  | 153/200 [02:59<00:56,  1.20s/it]\u001b[A\n",
      " 77%|███████▋  | 154/200 [03:00<00:54,  1.19s/it]\u001b[A\n",
      " 78%|███████▊  | 155/200 [03:02<00:53,  1.18s/it]\u001b[A\n",
      " 78%|███████▊  | 156/200 [03:03<00:51,  1.18s/it]\u001b[A\n",
      " 78%|███████▊  | 157/200 [03:04<00:50,  1.17s/it]\u001b[A\n",
      " 79%|███████▉  | 158/200 [03:05<00:49,  1.17s/it]\u001b[A\n",
      " 80%|███████▉  | 159/200 [03:06<00:47,  1.17s/it]\u001b[A\n",
      " 80%|████████  | 160/200 [03:07<00:46,  1.17s/it]\u001b[A\n",
      " 80%|████████  | 161/200 [03:08<00:45,  1.17s/it]\u001b[A\n",
      " 81%|████████  | 162/200 [03:10<00:44,  1.17s/it]\u001b[A\n",
      " 82%|████████▏ | 163/200 [03:11<00:43,  1.17s/it]\u001b[A\n",
      " 82%|████████▏ | 164/200 [03:12<00:41,  1.17s/it]\u001b[A\n",
      " 82%|████████▎ | 165/200 [03:13<00:40,  1.17s/it]\u001b[A\n",
      " 83%|████████▎ | 166/200 [03:14<00:39,  1.17s/it]\u001b[A\n",
      " 84%|████████▎ | 167/200 [03:15<00:38,  1.17s/it]\u001b[A\n",
      " 84%|████████▍ | 168/200 [03:17<00:37,  1.17s/it]\u001b[A\n",
      " 84%|████████▍ | 169/200 [03:18<00:36,  1.17s/it]\u001b[A\n",
      " 85%|████████▌ | 170/200 [03:19<00:34,  1.17s/it]\u001b[A\n",
      " 86%|████████▌ | 171/200 [03:20<00:33,  1.17s/it]\u001b[A\n",
      " 86%|████████▌ | 172/200 [03:21<00:32,  1.17s/it]\u001b[A\n",
      " 86%|████████▋ | 173/200 [03:22<00:31,  1.17s/it]\u001b[A\n",
      " 87%|████████▋ | 174/200 [03:24<00:30,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 175/200 [03:25<00:29,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 176/200 [03:26<00:27,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 177/200 [03:27<00:26,  1.17s/it]\u001b[A\n",
      " 89%|████████▉ | 178/200 [03:28<00:25,  1.17s/it]\u001b[A\n",
      " 90%|████████▉ | 179/200 [03:29<00:24,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 180/200 [03:31<00:23,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 181/200 [03:32<00:22,  1.17s/it]\u001b[A\n",
      " 91%|█████████ | 182/200 [03:33<00:20,  1.17s/it]\u001b[A\n",
      " 92%|█████████▏| 183/200 [03:34<00:19,  1.17s/it]\u001b[A\n",
      " 92%|█████████▏| 184/200 [03:35<00:18,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 185/200 [03:36<00:17,  1.17s/it]\u001b[A\n",
      " 93%|█████████▎| 186/200 [03:38<00:16,  1.17s/it]\u001b[A\n",
      " 94%|█████████▎| 187/200 [03:39<00:15,  1.17s/it]\u001b[A\n",
      " 94%|█████████▍| 188/200 [03:40<00:13,  1.17s/it]\u001b[A\n",
      " 94%|█████████▍| 189/200 [03:41<00:12,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 190/200 [03:42<00:11,  1.17s/it]\u001b[A\n",
      " 96%|█████████▌| 191/200 [03:43<00:10,  1.17s/it]\u001b[A\n",
      " 96%|█████████▌| 192/200 [03:45<00:09,  1.17s/it]\u001b[A\n",
      " 96%|█████████▋| 193/200 [03:46<00:08,  1.17s/it]\u001b[A\n",
      " 97%|█████████▋| 194/200 [03:47<00:06,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 195/200 [03:48<00:05,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 196/200 [03:49<00:04,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 197/200 [03:50<00:03,  1.17s/it]\u001b[A\n",
      " 99%|█████████▉| 198/200 [03:52<00:02,  1.17s/it]\u001b[A\n",
      "100%|█████████▉| 199/200 [03:53<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 200/200 [03:54<00:00,  1.17s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(),lr=0.01)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "seq_dim = 30\n",
    "num_epochs = 200\n",
    "\n",
    "train_losses_iterwise = []\n",
    "recall_iterwise = []\n",
    "precision_iterwise = []\n",
    "accuracy_iterwise = []\n",
    "f1score_iterwise = []\n",
    "val_losses_iterwise = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for i, (text,label,lengths) in enumerate(tl):\n",
    "\n",
    "        text = Variable(text.view(-1, seq_dim, 1)).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "        \n",
    "#         print(sexism_label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text)\n",
    "        \n",
    "#         print(outputs)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        train_losses.append(loss.data.cpu())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        allLabels = []\n",
    "        allPreds = []\n",
    "        probPreds = []\n",
    "\n",
    "        for i, (text,label,lengths) in enumerate(vl):\n",
    "            labels=[]\n",
    "            text = Variable(text.view(-1, seq_dim, 1)).to(device)\n",
    "            label = Variable(label).to(device)\n",
    "\n",
    "            predicted = model(text)\n",
    "            predicted =  torch.softmax(predicted,1)\n",
    "            probPreds.append(predicted)\n",
    "            predicted = torch.max(predicted, 1)[1].cpu().numpy().tolist()\n",
    "    #                 print(predicted)\n",
    "    #                 print(sexism_label)\n",
    "            allLabels += (label.cpu().numpy().tolist())\n",
    "            allPreds += (predicted)\n",
    "\n",
    "        valacc = accuracy_score(allLabels, allPreds)\n",
    "        recscore = recall_score(allLabels, allPreds,average='macro')\n",
    "        precscore = precision_score(allLabels, allPreds,average='macro')\n",
    "        f1score = f1_score(allLabels, allPreds,average='macro')\n",
    "#         roc = roc_auc_score(allLabels,allPreds)\n",
    "        cr = classification_report(allLabels, allPreds)\n",
    "        print(f'acc: {valacc} F1 {f1score}')\n",
    "        print(cr)\n",
    "\n",
    "        train_losses_iterwise.append(np.mean(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = model.getScores(text[11].reshape(1,30,1)).to(device).detach().cpu().reshape(1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "plt.matshow(wgts, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "fakenews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
