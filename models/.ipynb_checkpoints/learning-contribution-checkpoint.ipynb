{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import preprocessor as p\n",
    "import numpy as np\n",
    "import pandas\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    p.set_options(p.OPT.URL,p.OPT.MENTION,p.OPT.EMOJI,p.OPT.HASHTAG)\n",
    "    return p.tokenize(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24778</td>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24779</td>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24780</td>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24781</td>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24782</td>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('../HS_labeled_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI ,p.OPT.HASHTAG)\n",
    "    return p.tokenize(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer(split_text):\n",
    "    sent2idx = []\n",
    "    for w in split_text:\n",
    "        if w.lower() in word2idx:\n",
    "            sent2idx.append(word2idx[w.lower()])\n",
    "        else:\n",
    "            sent2idx.append(word2idx['_UNK'])\n",
    "            \n",
    "    return sent2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22447</td>\n",
       "      <td>22922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wagwuan bitches...!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19217</td>\n",
       "      <td>19645</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @iamTHATprettyMF: them other bitches aint g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16445</td>\n",
       "      <td>16821</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MickeyChristmas: Time to go to the studio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4415</td>\n",
       "      <td>4546</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@PinchSuckBlow lmoa @ high as giraffe pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15493</td>\n",
       "      <td>15857</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @HipHopIsDeaddd: Top ten rappers With no ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22680</td>\n",
       "      <td>23158</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>When a niggah think he gon come in-between me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"@MikelaHenry: but what if he actually does ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18864</td>\n",
       "      <td>19282</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @davis_lyndsi: Lol she blocked you little b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4639</td>\n",
       "      <td>4776</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@Sammytbh you're not fucking relevant... you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15150</td>\n",
       "      <td>15508</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @FREECEV: bitch get off twitter and text me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18587 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "22447       22922      3            0                   2        1      1   \n",
       "19217       19645      3            0                   3        0      1   \n",
       "16445       16821      3            0                   3        0      1   \n",
       "4415         4546      3            0                   3        0      1   \n",
       "15493       15857      3            0                   3        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "22680       23158      3            1                   2        0      1   \n",
       "193           195      3            0                   3        0      1   \n",
       "18864       19282      3            0                   3        0      1   \n",
       "4639         4776      3            0                   3        0      1   \n",
       "15150       15508      3            0                   3        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "22447                                Wagwuan bitches...!  \n",
       "19217  RT @iamTHATprettyMF: them other bitches aint g...  \n",
       "16445  RT @MickeyChristmas: Time to go to the studio ...  \n",
       "4415         @PinchSuckBlow lmoa @ high as giraffe pussy  \n",
       "15493  RT @HipHopIsDeaddd: Top ten rappers With no ho...  \n",
       "...                                                  ...  \n",
       "22680  When a niggah think he gon come in-between me ...  \n",
       "193    \"@MikelaHenry: but what if he actually does ch...  \n",
       "18864  RT @davis_lyndsi: Lol she blocked you little b...  \n",
       "4639   @Sammytbh you're not fucking relevant... you g...  \n",
       "15150  RT @FREECEV: bitch get off twitter and text me...  \n",
       "\n",
       "[18587 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "100%|██████████| 18587/18587 [00:00<00:00, 139770.78it/s]\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train['clean_text'] = train.tweet.apply(lambda x: preprocess(x.lower().strip()))\n",
    "\n",
    "words = Counter()\n",
    "for sent in tqdm(train.clean_text.values):\n",
    "    words.update(w.lower() for w in sent)\n",
    "   \n",
    "# sort with most frequently occuring words first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# add <pad> and <unk> token to vocab which will be used later\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "train['sentence2idx'] = train.clean_text.apply(lambda x: indexer(x))\n",
    "train['length'] = train.clean_text.apply(lambda x: len(x))\n",
    "train['label'] = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "valid['clean_text'] = valid.tweet.apply(lambda x: preprocess(x.strip()))\n",
    "\n",
    "valid['sentence2idx'] = valid.clean_text.apply(lambda x: indexer(x))\n",
    "valid['length'] = valid.clean_text.apply(lambda x: len(x))\n",
    "valid['label'] = valid['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df, maxlen=30):\n",
    "        self.maxlen = maxlen\n",
    "        self.df = df\n",
    "#         print('Padding')\n",
    "        self.df['padded_text'] = self.df.sentence2idx.apply(lambda x: self.pad_data(x))\n",
    "        self.padded_text = list(self.df.padded_text)\n",
    "        self.labels = list(self.df.label)\n",
    "        self.lengths = list(self.df.length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         lens = self.df.length[idx]\n",
    "        X = self.padded_text[idx]\n",
    "        y = self.labels[idx]\n",
    "        lens = self.lengths[idx]\n",
    "        return X,y,lens\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_loader = VectorizeData(train)\n",
    "valid_loader = VectorizeData(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "tl = DataLoader(dataset=train_loader, batch_size=100, shuffle=True)\n",
    "print(len(tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "vl = DataLoader(dataset=valid_loader, batch_size=100, shuffle=False)\n",
    "print(len(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[   4,    5, 9286,  ...,    0,    0,    0],\n",
      "        [   4,    5,   45,  ...,    0,    0,    0],\n",
      "        [   4,    5,   46,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 537, 5542,  174,  ...,    0,    0,    0],\n",
      "        [  48,   42,   10,  ...,    0,    0,    0],\n",
      "        [  70,   71,    9,  ...,    0,    0,    0]]), tensor([2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), tensor([19, 15, 10, 22, 12, 24,  5,  7, 15,  6,  7,  7, 15, 11, 20,  4,  4, 10,\n",
      "        18, 17, 11, 12, 23, 18, 11,  5, 15, 26, 22,  9, 18, 16, 11, 13,  8,  8,\n",
      "        20,  8, 22, 22,  9, 20, 21,  5, 20, 13,  8, 29, 10, 12, 27,  6, 10, 33,\n",
      "        13, 10, 16,  6, 14, 17, 16, 24, 10,  9, 18,  7, 20, 22, 16, 21, 16,  3,\n",
      "        13, 24, 16,  7, 11,  5, 12, 18, 10, 24,  4, 11, 12, 18, 22, 14,  4, 21,\n",
      "        17, 21,  8, 20, 17, 14, 27,  6, 20, 17])]\n"
     ]
    }
   ],
   "source": [
    "for i, samples in enumerate(tl):\n",
    "    print(i)\n",
    "    print(samples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[   4,    5,  180,  ...,    0,    0,    0],\n",
      "        [   1,    6,  350,  ...,    0,    0,    0],\n",
      "        [   2,    2,    2,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1953,   14,    7,  ...,    0,    0,    0],\n",
      "        [   4,    5,  196,  ...,    0,    0,    0],\n",
      "        [   1,   71,   63,  ...,    0,    0,    0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2,\n",
      "        2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), tensor([15, 14,  8, 14, 26, 12,  9, 19, 13,  6, 20, 15, 12,  6, 22, 26, 11, 11,\n",
      "        24, 14, 17, 21,  9, 25,  5, 20, 19, 11,  5,  4, 15, 11, 11,  7, 19,  8,\n",
      "        28,  6,  8, 22, 12,  5, 30, 10, 17,  9,  7, 11,  9,  9, 22,  5,  2, 14,\n",
      "        26,  8,  7, 10, 12,  8, 17, 24,  3, 10, 17, 14,  9, 14, 10,  7, 13,  9,\n",
      "         9, 11, 24, 16, 27, 12, 28, 11, 14, 21, 15, 26, 10, 13, 22, 13, 17,  8,\n",
      "        10,  6, 26, 11,  9, 20, 15, 13, 16, 25])]\n"
     ]
    }
   ],
   "source": [
    "for i, samples in enumerate(vl):\n",
    "    print(i)\n",
    "    print(samples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePMIMatrix(listOfTokenizedSentences):\n",
    "    wordCounts = defaultdict(lambda:0)\n",
    "    \n",
    "    print('Calculating Word Probabilities')\n",
    "    for tokenizedSent in tqdm(listOfTokenizedSentences):\n",
    "        for word in set(tokenizedSent):\n",
    "            wordCounts[word] += 1\n",
    "            \n",
    "    for key in wordCounts:\n",
    "        wordCounts[key] = wordCounts[key] / len(listOfTokenizedSentences)\n",
    "    \n",
    "    pairwiseCounts = defaultdict(lambda:defaultdict(lambda:0))\n",
    "    \n",
    "    print('Calculating PairWise Probabilities')\n",
    "    for tokenizedSent in tqdm(listOfTokenizedSentences):\n",
    "        sentWords = set(tokenizedSent)\n",
    "        \n",
    "        for i in sentWords:\n",
    "            for j in sentWords:\n",
    "                pairwiseCounts[i][j] += 1 / len(listOfTokenizedSentences)\n",
    "        \n",
    "    return wordCounts, pairwiseCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18587/18587 [00:00<00:00, 131399.85it/s]\n",
      "  0%|          | 0/18587 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Word Probabilities\n",
      "Calculating PairWise Probabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18587/18587 [00:02<00:00, 8644.80it/s]\n"
     ]
    }
   ],
   "source": [
    "a,b = computePMIMatrix(list(train['clean_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPMI(w1,w2):\n",
    "    try:\n",
    "        return max( 0,log(b[w1][w2]) - (log(a[w1])+log(a[w2])) )\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    # return sparse_to_tuple(adj_normalized)\n",
    "    return adj_normalized.A\n",
    "\n",
    "def chebyshev_polynomials(adj, k):\n",
    "    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices (tuple representation).\"\"\"\n",
    "    print(\"Calculating Chebyshev polynomials up to order {}...\".format(k))\n",
    "\n",
    "    adj_normalized = normalize_adj(adj)\n",
    "    laplacian = sp.eye(adj.shape[0]) - adj_normalized\n",
    "    largest_eigval, _ = eigsh(laplacian, 1, which='LM')\n",
    "    scaled_laplacian = (\n",
    "        2. / largest_eigval[0]) * laplacian - sp.eye(adj.shape[0])\n",
    "\n",
    "    t_k = list()\n",
    "    # t_k.append(sp.eye(adj.shape[0]))\n",
    "    # t_k.append(scaled_laplacian)\n",
    "    t_k.append(sp.eye(adj.shape[0]).A)\n",
    "    t_k.append(scaled_laplacian.A)\n",
    "\n",
    "    def chebyshev_recurrence(t_k_minus_one, t_k_minus_two, scaled_lap):\n",
    "        s_lap = sp.csr_matrix(scaled_lap, copy=True)\n",
    "        return 2 * s_lap.dot(t_k_minus_one) - t_k_minus_two\n",
    "\n",
    "    for i in range(2, k+1):\n",
    "        t_k.append(chebyshev_recurrence(t_k[-1], t_k[-2], scaled_laplacian))\n",
    "\n",
    "    # return sparse_to_tuple(t_k)\n",
    "    return t_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecArch(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, bidir, rnnType,device):\n",
    "        super(RecArch, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.rnnType = rnnType\n",
    "        self.bidirectional = bidir\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.numDirs = 2\n",
    "        else:\n",
    "            self.numDirs = 1\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, embedding_dim)\n",
    "        \n",
    "        if self.rnnType == 'lstm':\n",
    "            self.recNN = nn.LSTM(embedding_dim,hidden_dim, num_layers,batch_first=True,bidirectional=self.bidirectional)\n",
    "            \n",
    "        if self.rnnType == 'gru':\n",
    "            self.recNN = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True,bidirectional=self.bidirectional)\n",
    "            \n",
    "        if self.rnnType == 'rnn':\n",
    "            self.recNN = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True, nonlinearity='tanh',bidirectional=self.bidirectional)\n",
    "        \n",
    "        self.fc = nn.Linear(self.numDirs*hidden_dim,output_dim)\n",
    "    \n",
    "    def encode(self,x):\n",
    "        embs = self.emb(x)\n",
    "        embs = embs.view(x.size(0),-1,self.embedding_dim).to(self.device)\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "        \n",
    "        if self.rnnType == 'lstm':        \n",
    "            c0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "            \n",
    "            out,(hn,cn) = self.recNN(embs,(h0,c0))\n",
    "        \n",
    "        else:\n",
    "            out, hn = self.recNN(embs, h0)\n",
    "        \n",
    "#         print(out[:,-1,:].shape)\n",
    "        return out[:, -1, :]\n",
    "    \n",
    "    def forward(self,x):\n",
    "        embs = self.emb(x)\n",
    "        embs = embs.view(x.size(0),-1,self.embedding_dim).to(self.device)\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "        \n",
    "        if self.rnnType == 'lstm':        \n",
    "            c0 = Variable(torch.zeros(self.numDirs*self.num_layers,x.size(0),self.hidden_dim),requires_grad=True).to(self.device)\n",
    "            \n",
    "            out,(hn,cn) = self.recNN(embs,(h0,c0))\n",
    "        \n",
    "        else:\n",
    "            out, hn = self.recNN(embs, h0)\n",
    "        \n",
    "#         print(out[:,-1,:].shape)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal combination seems to be with GRU of 50 units and 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 256\n",
    "n_hidden = 50\n",
    "n_out = 3\n",
    "num_layers = 1\n",
    "rnnType = 'gru'\n",
    "bidir = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:1'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecArch(\n",
       "  (emb): Embedding(27649, 256)\n",
       "  (recNN): GRU(256, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecArch(vocab_size,embedding_dim,n_hidden,n_out,num_layers,bidir,rnnType,device)\n",
    "model = model.to(device)\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "  0%|          | 1/200 [00:01<03:21,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       332\n",
      "           1       0.90      0.94      0.92      4826\n",
      "           2       0.67      0.75      0.71      1038\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      6196\n",
      "   macro avg       0.52      0.56      0.54      6196\n",
      "weighted avg       0.81      0.85      0.83      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [00:42<02:09,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.26      0.20       332\n",
      "           1       0.90      0.91      0.90      4826\n",
      "           2       0.80      0.62      0.70      1038\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6196\n",
      "   macro avg       0.62      0.60      0.60      6196\n",
      "weighted avg       0.84      0.82      0.83      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [01:26<01:40,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.21      0.19       332\n",
      "           1       0.89      0.92      0.91      4826\n",
      "           2       0.80      0.62      0.70      1038\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6196\n",
      "   macro avg       0.62      0.58      0.60      6196\n",
      "weighted avg       0.84      0.83      0.83      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151/200 [02:14<00:49,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.24      0.20       332\n",
      "           1       0.90      0.91      0.90      4826\n",
      "           2       0.79      0.64      0.70      1038\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6196\n",
      "   macro avg       0.62      0.60      0.60      6196\n",
      "weighted avg       0.84      0.83      0.83      6196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:02<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(),lr=0.01)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "seq_dim = 30\n",
    "num_epochs = 200\n",
    "\n",
    "train_losses_iterwise = []\n",
    "recall_iterwise = []\n",
    "precision_iterwise = []\n",
    "accuracy_iterwise = []\n",
    "f1score_iterwise = []\n",
    "val_losses_iterwise = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for i, (text,label,lengths) in enumerate(tl):\n",
    "\n",
    "        text = Variable(text.view(-1, seq_dim, 1)).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "        \n",
    "#         print(sexism_label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text)\n",
    "        \n",
    "#         print(outputs)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        train_losses.append(loss.data.cpu())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        allLabels = []\n",
    "        allPreds = []\n",
    "        probPreds = []\n",
    "\n",
    "        for i, (text,label,lengths) in enumerate(vl):\n",
    "            labels=[]\n",
    "            text = Variable(text.view(-1, seq_dim, 1)).to(device)\n",
    "            label = Variable(label).to(device)\n",
    "\n",
    "            predicted = model(text)\n",
    "            predicted =  torch.softmax(predicted,1)\n",
    "            probPreds.append(predicted)\n",
    "            predicted = torch.max(predicted, 1)[1].cpu().numpy().tolist()\n",
    "    #                 print(predicted)\n",
    "    #                 print(sexism_label)\n",
    "            allLabels += (label.cpu().numpy().tolist())\n",
    "            allPreds += (predicted)\n",
    "\n",
    "        valacc = accuracy_score(allLabels, allPreds)\n",
    "        recscore = recall_score(allLabels, allPreds,average='macro')\n",
    "        precscore = precision_score(allLabels, allPreds,average='macro')\n",
    "        f1score = f1_score(allLabels, allPreds,average='macro')\n",
    "#         roc = roc_auc_score(allLabels,allPreds)\n",
    "        cr = classification_report(allLabels, allPreds)\n",
    "#         print(f'acc: {valacc} AUC {roc}')\n",
    "        print(cr)\n",
    "\n",
    "        train_losses_iterwise.append(np.mean(train_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = DataLoader(dataset=train_loader, batch_size=1, shuffle=True)\n",
    "vl = DataLoader(dataset=valid_loader, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAdjMatrix(text):\n",
    "    text = text.reshape(-1).tolist()\n",
    "    words = [idx2word[idx] for idx in text]\n",
    "    matrix = []\n",
    "    for i in range(len(words)):\n",
    "        row = []\n",
    "        for j in range(len(words)):\n",
    "            row.append(PPMI(words[i],words[j]))\n",
    "        row.append(1)\n",
    "        matrix.append(row)\n",
    "        \n",
    "    matrix.append([1 for i in range(len(words)+1)])\n",
    "    return preprocess_adj(np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size,seq_dim):\n",
    "        super(GraphConvLayer,self).__init__()\n",
    "        \n",
    "        self.attn = nn.parameter.Parameter(torch.FloatTensor(seq_dim, seq_dim))\n",
    "        self.weight = nn.parameter.Parameter(torch.FloatTensor(in_size, out_size))\n",
    "        var = 2./(self.weight.size(1)+self.weight.size(0))\n",
    "        self.weight.data.normal_(0,var)\n",
    "        var = 2./(self.attn.size(1)+self.attn.size(0))\n",
    "        self.attn.data.normal_(0,var)\n",
    "        \n",
    "    def forward(self,X,A_hat):\n",
    "        X = torch.mm(X, self.weight)\n",
    "        wgtScores = torch.mm(A_hat, self.attn)\n",
    "        out = F.relu(torch.mm(wgtScores,X))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def getScores(self,A_hat):\n",
    "        wgtScores = torch.mm(A_hat, self.attn)\n",
    "        return wgtScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvNet(nn.Module):\n",
    "    def __init__(self,feature_dim,seq_dim):\n",
    "        super(GraphConvNet, self).__init__()\n",
    "        self.graphlayer1 = GraphConvLayer(feature_dim,feature_dim,seq_dim)\n",
    "#         self.graphlayer2 = GraphConvLayer(feature_dim,feature_dim,seq_dim)        \n",
    "        self.fc = nn.Linear(50,3)\n",
    "        \n",
    "    def forward(self,X,A_hat):\n",
    "        A_hat = torch.tensor(A_hat).float()\n",
    "        X1 = self.graphlayer1(X,A_hat)\n",
    "#         X2 = self.graphlayer2(X1,A_hat)\n",
    "        \n",
    "        out = self.fc(X1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom GCN with Fixed Adj Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcnModel = GraphConvNet(50,31).to(device)\n",
    "# gcnModel.fc.load_state_dict(model.fc.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42a2c2309fa4f2a965a3e1374733582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39e5524941249e9830a13b63a6848f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18587.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.0169941862155112\n",
      "acc: 0.8190768237572628 f1 0.5985197199379442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 30\n",
    "\n",
    "optimizer = optim.Adam(gcnModel.parameters(), lr=0.02)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm_notebook(range(1)):\n",
    "    train_losses = []\n",
    "    for i, (text,label,lengths) in tqdm_notebook(enumerate(tl),total=len(tl)):\n",
    "        textencs = model.encode(text.reshape(seq_dim,-1,1).to(device))\n",
    "        sentenc = model.encode(text.reshape(-1, seq_dim, 1).to(device))\n",
    "        embeds = torch.cat([textencs,sentenc])\n",
    "        label = Variable(label).to(device)\n",
    "        \n",
    "        adj_matrix = torch.tensor(computeAdjMatrix(text)).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = gcnModel(embeds,adj_matrix)\n",
    "        \n",
    "        loss = criterion(outputs[-1].reshape(1,-1), label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "#         print(loss.item())\n",
    "    print(np.average(train_losses))\n",
    "    \n",
    "    allLabels = []\n",
    "    allPreds = []\n",
    "    probPreds = []\n",
    "\n",
    "    for i, (text,label,lengths) in enumerate(vl):\n",
    "        labels=[]\n",
    "        textencs = model.encode(text.reshape(seq_dim,-1,1).to(device))\n",
    "        sentenc = model.encode(text.reshape(-1, seq_dim, 1).to(device))\n",
    "        embeds = torch.cat([textencs,sentenc])\n",
    "        label = Variable(label).to(device)\n",
    "\n",
    "        outputs = gcnModel(embeds,adj_matrix)\n",
    "        predicted =  torch.softmax(outputs[-1].reshape(1,-1),1)\n",
    "        predicted = torch.max(predicted, 1)[1].cpu().numpy().tolist()\n",
    "        allLabels += (label.cpu().numpy().tolist())\n",
    "        allPreds += (predicted)\n",
    "\n",
    "    valacc = accuracy_score(allLabels, allPreds)\n",
    "    f1score = f1_score(allLabels, allPreds,average='macro')\n",
    "#         roc = roc_auc_score(allLabels,allPreds)\n",
    "    cr = classification_report(allLabels, allPreds)\n",
    "    print(f'acc: {valacc} f1 {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1006,   49,  582,   93,    3,    8,   41,    7,   47,   27,   13,  364,\n",
       "          57,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0948e-01, -3.1597e-01, -2.6983e-01, -7.3111e-02, -1.1880e-01,\n",
       "         -1.2854e-01, -4.5963e-01,  8.5850e-02,  5.3160e-01,  7.6355e-01,\n",
       "          2.7469e-01,  1.4725e-01,  2.7114e-01,  1.6409e-01,  4.7791e-02,\n",
       "         -4.7471e-02,  1.6535e-01, -3.8072e-02,  1.1285e-01, -1.0319e-01,\n",
       "          8.7207e-02,  2.0821e-01, -7.0196e-03,  3.5564e-01,  3.1589e-01,\n",
       "          3.9203e-01,  2.7206e-01,  3.6222e-01,  6.6314e-01,  6.7146e-01,\n",
       "         -2.6333e+00],\n",
       "        [ 2.3252e-01, -4.0026e-01, -1.3653e-01,  5.5988e-02, -2.4847e-01,\n",
       "          3.0930e-02, -4.8028e-01,  4.9453e-02,  5.8559e-01,  5.4081e-01,\n",
       "          1.4833e-01, -3.3830e-02,  1.5063e-01,  1.2295e-01,  5.5491e-02,\n",
       "         -1.2272e-01,  2.3699e-01,  1.3875e-01,  2.2470e-01, -6.6741e-02,\n",
       "          8.2926e-02,  1.9172e-01, -3.3727e-03,  3.8287e-01,  3.5468e-01,\n",
       "          4.2416e-01,  2.7319e-01,  3.7989e-01,  7.3285e-01,  7.6118e-01,\n",
       "         -2.2001e+00],\n",
       "        [ 3.9936e-01, -5.1535e-01, -3.9741e-01, -8.2479e-02, -3.5829e-01,\n",
       "         -2.5633e-01, -6.6899e-01, -1.4011e-01,  6.2025e-01,  8.8022e-01,\n",
       "          2.4689e-01,  7.8044e-02,  3.6156e-01,  3.0147e-01,  1.7358e-01,\n",
       "          5.9406e-02,  3.2218e-01,  1.3047e-01,  2.2693e-01,  3.8544e-02,\n",
       "          2.6030e-01,  3.4040e-01,  1.8900e-01,  5.1280e-01,  5.0670e-01,\n",
       "          5.8125e-01,  4.5517e-01,  5.6981e-01,  8.5441e-01,  8.4217e-01,\n",
       "         -3.2810e+00],\n",
       "        [ 3.0226e-01, -1.0793e-01, -1.3242e-01, -9.0973e-02, -2.0681e-01,\n",
       "         -2.4925e-01, -4.7605e-01, -9.7785e-02,  3.5765e-01,  6.1263e-01,\n",
       "          4.9637e-02, -4.2504e-02,  1.8940e-01,  1.7430e-01,  8.9173e-02,\n",
       "         -3.2925e-02,  2.4301e-01,  2.5677e-02,  9.7840e-02, -4.4260e-02,\n",
       "          1.3286e-01,  1.8374e-01,  4.6294e-02,  3.4831e-01,  3.4914e-01,\n",
       "          4.2399e-01,  3.1534e-01,  4.1259e-01,  6.6917e-01,  6.5647e-01,\n",
       "         -2.7196e+00],\n",
       "        [ 6.6352e-01, -5.7640e-01, -5.8732e-01, -1.9069e-01, -6.1989e-01,\n",
       "         -3.6133e-01, -1.0905e+00, -2.2593e-01,  8.5092e-01,  1.2058e+00,\n",
       "          2.7379e-01,  6.1316e-02,  4.5643e-01,  3.7279e-01,  2.0930e-01,\n",
       "          1.4492e-02,  4.2797e-01,  1.2099e-01,  2.5324e-01, -9.5718e-03,\n",
       "          3.0963e-01,  4.2580e-01,  1.8940e-01,  6.9360e-01,  6.7765e-01,\n",
       "          7.9602e-01,  6.0074e-01,  7.7830e-01,  1.2490e+00,  1.2292e+00,\n",
       "         -4.9140e+00],\n",
       "        [ 3.7891e-01, -2.8989e-01, -4.5308e-01, -2.7108e-01, -6.2314e-01,\n",
       "         -3.8603e-01, -6.6712e-01, -2.6493e-01,  3.9530e-01,  5.3960e-01,\n",
       "          9.8674e-02,  1.0403e-02,  1.9837e-01,  1.5877e-01,  8.8327e-02,\n",
       "          3.3550e-02,  1.7130e-01,  2.0942e-02,  4.7178e-02, -2.8166e-03,\n",
       "          1.7967e-01,  2.1101e-01,  1.1795e-01,  3.2234e-01,  3.2394e-01,\n",
       "          3.6764e-01,  2.5796e-01,  3.7240e-01,  6.1384e-01,  5.7858e-01,\n",
       "         -2.6497e+00],\n",
       "        [ 4.4090e-01, -2.5007e-01, -4.4061e-01, -9.3539e-02, -3.9705e-01,\n",
       "         -1.9572e-01, -7.1909e-01, -2.1169e-01,  4.2261e-01,  6.3948e-01,\n",
       "          7.3218e-02,  1.9170e-02,  2.6906e-01,  2.3471e-01,  1.5593e-01,\n",
       "          6.6162e-02,  2.3161e-01,  5.3500e-02,  8.5082e-02,  5.0872e-02,\n",
       "          2.1325e-01,  2.3816e-01,  1.5411e-01,  3.7421e-01,  3.6632e-01,\n",
       "          4.2826e-01,  3.3534e-01,  4.3239e-01,  6.8206e-01,  6.5526e-01,\n",
       "         -2.8832e+00],\n",
       "        [ 6.5357e-01, -5.6937e-01, -5.6924e-01, -1.8515e-01, -5.9426e-01,\n",
       "         -3.4862e-01, -1.0924e+00, -2.1622e-01,  8.6241e-01,  1.2068e+00,\n",
       "          2.8542e-01,  8.1714e-02,  4.6488e-01,  3.8184e-01,  2.2019e-01,\n",
       "          2.8684e-02,  4.3047e-01,  1.2885e-01,  2.6118e-01,  2.5021e-03,\n",
       "          3.1760e-01,  4.3320e-01,  1.9774e-01,  6.9659e-01,  6.8085e-01,\n",
       "          7.9687e-01,  6.0343e-01,  7.7910e-01,  1.2466e+00,  1.2275e+00,\n",
       "         -4.9157e+00],\n",
       "        [ 1.6922e-01, -1.7681e-01, -5.1521e-02, -3.7640e-02, -2.3924e-01,\n",
       "         -1.8157e-01, -6.8907e-01, -1.8641e-01,  5.8851e-01,  4.9352e-01,\n",
       "          2.4349e-01,  1.7894e-01,  2.5741e-01,  2.4452e-01,  1.8286e-01,\n",
       "          1.5701e-01,  2.5062e-01,  1.4587e-01,  1.7972e-01,  1.3636e-01,\n",
       "          2.6122e-01,  2.9469e-01,  1.9548e-01,  3.7169e-01,  3.6415e-01,\n",
       "          4.0235e-01,  3.2129e-01,  3.8536e-01,  5.6829e-01,  5.6857e-01,\n",
       "         -2.6868e+00],\n",
       "        [-2.1258e-02, -3.8536e-01, -1.5344e-01,  5.2155e-02, -2.1850e-01,\n",
       "         -2.4756e-01, -6.0754e-01, -8.8227e-02,  5.7778e-01,  5.1639e-01,\n",
       "          9.0734e-02,  1.4779e-02,  1.9538e-01,  1.5952e-01,  8.3767e-02,\n",
       "          3.1876e-02,  1.1683e-01, -2.6937e-02,  2.9828e-02,  1.4155e-02,\n",
       "          1.5939e-01,  1.8594e-01,  9.1293e-02,  2.8403e-01,  2.6662e-01,\n",
       "          3.1810e-01,  2.4075e-01,  3.0928e-01,  5.2470e-01,  5.1495e-01,\n",
       "         -2.7547e+00],\n",
       "        [ 6.3472e-01, -5.5929e-01, -5.6803e-01, -1.8811e-01, -5.8920e-01,\n",
       "         -3.5009e-01, -1.0919e+00, -2.1005e-01,  8.6866e-01,  1.2103e+00,\n",
       "          2.8068e-01,  7.5019e-02,  4.5773e-01,  3.7503e-01,  2.1403e-01,\n",
       "          2.1457e-02,  4.2488e-01,  1.2359e-01,  2.5599e-01, -3.9033e-03,\n",
       "          3.1142e-01,  4.2657e-01,  1.9189e-01,  6.8996e-01,  6.7391e-01,\n",
       "          7.9039e-01,  5.9737e-01,  7.7267e-01,  1.2394e+00,  1.2202e+00,\n",
       "         -4.9349e+00],\n",
       "        [ 9.9040e-03, -1.9054e-02, -2.9444e-02, -4.8152e-02,  9.0058e-02,\n",
       "         -1.4198e-01, -3.2900e-01,  4.2806e-02,  4.8936e-01,  6.9311e-01,\n",
       "          7.3440e-02,  4.8620e-02,  2.7480e-01,  2.4837e-01,  1.5522e-01,\n",
       "          9.4011e-02,  2.4352e-01,  4.7576e-02,  1.3006e-01,  5.6570e-02,\n",
       "          2.0396e-01,  2.2418e-01,  1.2575e-01,  3.5793e-01,  3.2631e-01,\n",
       "          4.0517e-01,  3.2922e-01,  3.9308e-01,  6.3786e-01,  6.3235e-01,\n",
       "         -2.8434e+00],\n",
       "        [ 3.2423e-02,  7.7063e-02, -8.7136e-02, -1.0122e-01, -6.4089e-02,\n",
       "         -2.7287e-01, -4.1242e-01,  9.3624e-02,  4.6705e-01,  5.7689e-01,\n",
       "          1.0967e-01,  5.2769e-02,  1.2767e-01,  1.1648e-01,  6.8504e-02,\n",
       "          4.7174e-02,  9.4364e-02, -1.3736e-02,  1.7847e-02,  5.5317e-02,\n",
       "          1.7047e-01,  1.9791e-01,  1.0512e-01,  2.6940e-01,  2.7448e-01,\n",
       "          2.9014e-01,  2.1741e-01,  2.8630e-01,  4.4256e-01,  4.2871e-01,\n",
       "         -2.8687e+00],\n",
       "        [-3.4927e-02,  6.9239e-02, -9.0504e-02, -1.0567e-01, -8.3903e-02,\n",
       "         -2.6536e-01, -4.1240e-01,  6.5925e-02,  4.8146e-01,  5.8116e-01,\n",
       "          9.2275e-02,  4.6485e-02,  9.6274e-02,  1.2672e-01,  6.8011e-02,\n",
       "          3.5655e-02,  1.0881e-01, -9.0897e-03,  3.7822e-02,  3.4315e-02,\n",
       "          1.6390e-01,  1.8349e-01,  7.9951e-02,  2.7428e-01,  2.6899e-01,\n",
       "          3.0155e-01,  2.1275e-01,  2.8422e-01,  5.0884e-01,  5.0721e-01,\n",
       "         -2.8547e+00],\n",
       "        [-1.0308e-02,  6.4159e-02, -2.5539e-01, -9.6519e-02, -1.3657e-01,\n",
       "         -2.2771e-01, -4.5208e-01,  7.3091e-02,  5.2240e-01,  5.5760e-01,\n",
       "          1.4013e-01,  5.2724e-02,  9.8231e-02,  8.5274e-02,  3.3122e-02,\n",
       "          1.7049e-02,  7.2024e-02, -1.5797e-02,  4.3846e-02,  3.1573e-02,\n",
       "          1.5747e-01,  2.0637e-01,  9.2223e-02,  2.7073e-01,  2.5853e-01,\n",
       "          2.7839e-01,  1.8948e-01,  2.6273e-01,  4.4966e-01,  4.4611e-01,\n",
       "         -2.9368e+00],\n",
       "        [-4.7261e-03,  1.5340e-01, -1.9855e-01, -1.0701e-01, -1.0433e-01,\n",
       "         -1.7691e-01, -4.7735e-01,  4.8250e-02,  4.8748e-01,  5.6427e-01,\n",
       "          1.2355e-01,  4.8640e-02,  7.6813e-02,  9.4560e-02,  1.6729e-02,\n",
       "         -4.4347e-03,  7.7437e-02,  5.3243e-03,  5.8675e-02, -1.7446e-02,\n",
       "          1.0579e-01,  1.4636e-01,  4.8815e-02,  2.1639e-01,  2.1146e-01,\n",
       "          2.4183e-01,  1.5177e-01,  2.2482e-01,  4.0130e-01,  4.0033e-01,\n",
       "         -2.9528e+00],\n",
       "        [ 1.8010e-02,  7.6350e-02, -2.9878e-02, -1.2513e-01,  2.6255e-03,\n",
       "         -2.0492e-01, -4.3812e-01,  1.0742e-01,  3.8602e-01,  6.6183e-01,\n",
       "          1.0480e-01,  3.7424e-02,  1.5994e-01,  1.3477e-01,  1.5234e-02,\n",
       "         -2.6705e-02,  7.4741e-03, -1.1713e-01, -4.8402e-02, -9.0407e-02,\n",
       "          1.7936e-02,  4.6596e-02, -4.3308e-02,  1.3640e-01,  1.3200e-01,\n",
       "          1.7461e-01,  1.0463e-01,  1.6909e-01,  3.3816e-01,  3.2730e-01,\n",
       "         -2.9032e+00],\n",
       "        [-2.9653e-02,  1.2470e-01, -9.2452e-04, -1.6853e-01, -9.5155e-03,\n",
       "         -2.1110e-01, -4.6181e-01,  8.1806e-02,  3.8251e-01,  6.5534e-01,\n",
       "          8.0447e-02,  4.8910e-02,  1.4948e-01,  1.3959e-01,  2.1388e-02,\n",
       "         -1.8815e-02, -1.3148e-02, -1.3291e-01, -5.7389e-02, -1.0764e-01,\n",
       "          1.1663e-02,  2.6901e-02, -5.8885e-02,  1.1817e-01,  9.8631e-02,\n",
       "          1.4215e-01,  7.2282e-02,  1.3172e-01,  3.3713e-01,  3.3043e-01,\n",
       "         -2.9159e+00],\n",
       "        [ 4.8505e-02, -6.9013e-02, -1.5833e-01, -9.2829e-02, -1.3353e-01,\n",
       "         -3.7040e-01, -2.6585e-01,  1.1084e-01,  4.7663e-01,  6.3918e-01,\n",
       "          4.4385e-02, -4.4179e-03,  2.1980e-01,  1.7717e-01,  4.9642e-02,\n",
       "          1.0541e-01,  2.6885e-02, -9.9173e-02, -1.1217e-01,  5.8210e-02,\n",
       "          1.7829e-01,  1.9846e-01,  1.0566e-01,  2.7986e-01,  2.7120e-01,\n",
       "          2.9656e-01,  2.1410e-01,  2.8539e-01,  4.9214e-01,  4.8292e-01,\n",
       "         -2.8079e+00],\n",
       "        [ 7.3002e-02, -3.8753e-02, -1.5251e-01, -2.9164e-02, -1.3160e-01,\n",
       "         -3.5811e-01, -2.6995e-01,  1.0763e-01,  4.7758e-01,  6.6969e-01,\n",
       "          6.0281e-02, -1.9589e-02,  2.3211e-01,  1.7601e-01,  4.8875e-02,\n",
       "          1.1469e-01,  2.6349e-02, -9.7762e-02, -1.1922e-01,  4.7963e-02,\n",
       "          1.7662e-01,  1.9044e-01,  1.1774e-01,  2.6544e-01,  2.5131e-01,\n",
       "          2.8085e-01,  1.9444e-01,  2.7313e-01,  4.8564e-01,  4.6788e-01,\n",
       "         -2.8475e+00],\n",
       "        [-1.5025e-03, -6.9530e-02, -1.2036e-01, -1.6593e-01, -1.0424e-01,\n",
       "         -3.7466e-01, -2.9437e-01,  7.5594e-02,  4.6963e-01,  6.1038e-01,\n",
       "          4.5401e-02, -7.0048e-03,  2.0642e-01,  1.6463e-01,  5.5228e-02,\n",
       "          8.2218e-02,  7.1896e-03, -1.0861e-01, -1.0314e-01,  7.9498e-02,\n",
       "          2.0728e-01,  2.3676e-01,  1.3860e-01,  3.1538e-01,  3.0383e-01,\n",
       "          3.3192e-01,  2.5990e-01,  3.1924e-01,  5.1783e-01,  5.1483e-01,\n",
       "         -2.7219e+00],\n",
       "        [ 6.8287e-02, -1.3104e-01, -9.0526e-02, -3.4557e-02,  1.3723e-03,\n",
       "         -3.1641e-01, -2.4034e-01,  7.5518e-02,  4.1149e-01,  6.7343e-01,\n",
       "          5.7321e-02, -5.5581e-02,  2.2235e-01,  1.7115e-01,  5.1806e-02,\n",
       "          4.3308e-02,  8.6454e-02, -6.6782e-02, -4.9053e-02,  5.2019e-02,\n",
       "          1.8761e-01,  2.3981e-01,  1.1804e-01,  3.3943e-01,  3.3839e-01,\n",
       "          3.9156e-01,  3.0384e-01,  3.6967e-01,  5.5672e-01,  5.6223e-01,\n",
       "         -2.6912e+00],\n",
       "        [-3.4423e-03, -8.3843e-02, -1.3494e-01, -1.5576e-01, -1.6830e-01,\n",
       "         -3.5481e-01, -2.5499e-01,  9.9061e-02,  4.6796e-01,  5.9077e-01,\n",
       "          3.1610e-02,  4.8480e-03,  2.0749e-01,  1.6780e-01,  7.0560e-02,\n",
       "          9.7299e-02,  5.8623e-03, -6.0476e-02, -9.5826e-02,  6.9393e-02,\n",
       "          1.9835e-01,  2.2865e-01,  1.2643e-01,  3.0302e-01,  2.8471e-01,\n",
       "          3.1105e-01,  2.1191e-01,  2.8296e-01,  5.2340e-01,  5.3465e-01,\n",
       "         -2.7376e+00],\n",
       "        [ 9.1234e-03, -1.1998e-01, -2.3570e-01, -1.5699e-01, -9.4275e-02,\n",
       "         -3.3066e-01, -3.0692e-01,  6.7975e-02,  4.7909e-01,  5.6295e-01,\n",
       "          9.3803e-02,  1.4416e-02,  2.0372e-01,  9.5745e-02, -4.7964e-03,\n",
       "          2.1031e-02,  1.1260e-02, -1.1854e-01, -6.1804e-02,  6.2097e-02,\n",
       "          1.9501e-01,  2.8203e-01,  1.2045e-01,  3.3842e-01,  3.3988e-01,\n",
       "          3.5219e-01,  2.8402e-01,  3.4639e-01,  5.0797e-01,  5.0255e-01,\n",
       "         -2.7472e+00],\n",
       "        [ 6.1388e-02, -2.7523e-01, -1.6501e-01, -9.4444e-02,  3.1036e-02,\n",
       "         -3.1413e-01, -1.7707e-01,  8.0341e-02,  4.0187e-01,  6.3288e-01,\n",
       "          4.6870e-02, -4.2623e-02,  1.8549e-01,  1.3803e-01,  2.3539e-02,\n",
       "         -1.1882e-02,  1.5473e-01, -9.0675e-02,  1.3224e-02,  3.6262e-02,\n",
       "          1.5693e-01,  2.6581e-01,  2.8955e-02,  3.9111e-01,  4.2116e-01,\n",
       "          4.7352e-01,  3.7929e-01,  4.4537e-01,  6.3601e-01,  6.5128e-01,\n",
       "         -2.6122e+00],\n",
       "        [ 3.0126e-03, -2.3239e-01, -1.1903e-01, -6.4155e-02,  4.5763e-02,\n",
       "         -3.6467e-01, -1.8661e-01,  6.9178e-02,  3.9701e-01,  6.6825e-01,\n",
       "          1.4998e-02, -6.7878e-02,  1.9535e-01,  1.5933e-01,  4.4126e-02,\n",
       "          4.2883e-03,  1.5176e-01, -1.2988e-01, -1.8450e-02,  3.4656e-02,\n",
       "          1.7822e-01,  2.4839e-01,  4.2175e-02,  3.9208e-01,  4.0572e-01,\n",
       "          4.6623e-01,  3.7211e-01,  4.5013e-01,  6.9076e-01,  6.8198e-01,\n",
       "         -2.5892e+00],\n",
       "        [-6.1260e-04, -2.5915e-01, -1.4840e-01, -1.0472e-01,  3.4747e-02,\n",
       "         -3.3074e-01, -1.6961e-01,  5.9889e-02,  4.1377e-01,  6.5672e-01,\n",
       "          1.6505e-02, -5.5022e-02,  1.9799e-01,  1.5873e-01,  3.3464e-02,\n",
       "          2.5454e-03,  1.4862e-01, -1.2404e-01, -1.0562e-03,  2.6834e-02,\n",
       "          1.6348e-01,  2.4952e-01,  2.2924e-02,  3.9892e-01,  3.9757e-01,\n",
       "          4.6566e-01,  3.7140e-01,  4.3083e-01,  6.9267e-01,  7.1156e-01,\n",
       "         -2.5970e+00],\n",
       "        [ 4.9577e-02, -2.1797e-01, -8.0773e-02, -8.5892e-02,  7.2801e-02,\n",
       "         -3.5042e-01, -2.0895e-01,  1.0193e-01,  3.9509e-01,  6.4874e-01,\n",
       "          3.3003e-02, -6.0735e-02,  1.9129e-01,  1.4608e-01,  4.9911e-02,\n",
       "         -1.3778e-03,  1.5484e-01, -1.1955e-01, -1.8972e-02,  5.2434e-02,\n",
       "          1.7859e-01,  2.5768e-01,  5.6841e-02,  3.7966e-01,  4.2348e-01,\n",
       "          4.6618e-01,  3.8739e-01,  4.6264e-01,  6.1847e-01,  5.9863e-01,\n",
       "         -2.6148e+00],\n",
       "        [-1.1396e-01, -3.6927e-01, -2.7775e-01,  2.1644e-03, -1.3520e-01,\n",
       "         -3.5559e-01, -8.5937e-02,  1.9913e-02,  4.6106e-01,  6.4830e-01,\n",
       "         -1.5571e-03, -6.0022e-02,  1.9652e-01,  1.6739e-01,  7.1044e-03,\n",
       "         -4.6198e-03,  1.5476e-01, -1.0646e-01,  1.0605e-02, -5.3466e-02,\n",
       "          1.5296e-01,  2.2548e-01, -2.8354e-02,  4.2647e-01,  3.5438e-01,\n",
       "          4.5800e-01,  2.8205e-01,  3.8131e-01,  7.8290e-01,  8.1208e-01,\n",
       "         -2.5576e+00],\n",
       "        [-1.0971e-01, -3.8930e-01, -2.8405e-01,  1.1798e-02, -1.6049e-01,\n",
       "         -3.5739e-01, -9.3021e-02,  6.6002e-02,  4.6045e-01,  6.4595e-01,\n",
       "          8.2575e-03, -6.6894e-02,  1.9693e-01,  1.6333e-01,  1.3546e-02,\n",
       "         -1.6467e-02,  1.5286e-01, -9.7562e-02,  7.0067e-03, -5.2674e-02,\n",
       "          1.5025e-01,  2.1780e-01, -2.6422e-02,  4.2176e-01,  3.5435e-01,\n",
       "          4.5359e-01,  2.7437e-01,  3.8403e-01,  7.9140e-01,  8.1525e-01,\n",
       "         -2.5432e+00],\n",
       "        [ 3.8203e-01, -3.7569e-01, -6.0108e-01, -5.8865e-01, -3.7194e-01,\n",
       "         -1.1972e+00, -1.9443e+00,  2.1634e-01,  2.2766e+00,  3.0060e+00,\n",
       "          4.5152e-01,  1.3723e-01,  9.4400e-01,  7.8951e-01,  3.3440e-01,\n",
       "          2.0555e-01,  4.8165e-01, -2.1245e-01,  6.9232e-02,  1.9642e-01,\n",
       "          7.6494e-01,  1.0053e+00,  4.0918e-01,  1.4667e+00,  1.4460e+00,\n",
       "          1.6582e+00,  1.3032e+00,  1.5819e+00,  2.5195e+00,  2.5343e+00,\n",
       "         -1.3358e+01]], device='cuda:1', dtype=torch.float64,\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigf = torch.softmax(torch.mm(adj_matrix.double(), gcnModel.graphlayer1.attn.double()),1).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "plt.matshow(bigf, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying BSWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dixon_bsws = ['lesbian', 'gay', 'bisexual', 'transgender', 'trans', 'queer', 'lgbt', 'lgbtq', 'homosexual', 'straight', 'heterosexual', 'male', 'female', 'nonbinary',\n",
    "'african', 'african american', 'black', 'white', 'european', 'hispanic', 'latino', 'latina', 'latinx', 'mexican', 'canadian', 'american', 'asian', 'indian',\n",
    "'middle eastern', 'chinese', 'japanese', 'christian', 'muslim', 'jewish', 'buddhist', 'catholic', 'protestant', 'sikh', 'taoist', 'old', 'older', 'young',\n",
    "'younger', 'teenage', 'millenial', 'middle aged', 'elderly', 'blind', 'deaf', 'paralyzed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsws = {}\n",
    "for word in tqdm(word2idx):\n",
    "    vect = torch.tensor([word2idx[word]]).to(device)\n",
    "    textenc = model.encode(vect)\n",
    "    scores = torch.softmax(gcnModel.fc(textenc),1)\n",
    "    \n",
    "    if torch.max(scores) > 0.7 and torch.argmax(scores) == 0:\n",
    "        bsws[word] = torch.max(scores).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModelClassification(sentence):\n",
    "    tokens = preprocess(sentence.lower().strip())\n",
    "    output = model(torch.tensor([word2idx[x] for x in tokens]).reshape(1,-1).to(device))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGraphClassification(sentence):\n",
    "    tokens = preprocess(sentence.lower().strip())\n",
    "    text = torch.tensor([word2idx[x] for x in tokens]).reshape(1,-1).to(device)\n",
    "    \n",
    "    textencs = model.encode(text.reshape(len(tokens),-1,1).to(device))\n",
    "    sentenc = model.encode(text.reshape(-1, len(tokens), 1).to(device))\n",
    "    embeds = torch.cat([textencs,sentenc])\n",
    "\n",
    "    adj_matrix = torch.tensor(computeAdjMatrix(text)).to(device)\n",
    "    \n",
    "    outputs = gcnModel(embeds,adj_matrix)\n",
    "    \n",
    "    return outputs, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOAC(listOfTokenizedSentences, listOfLabels):\n",
    "    tfs = defaultdict(lambda:0)\n",
    "    dfs = defaultdict(lambda:0)\n",
    "    df_pos = defaultdict(lambda:0)\n",
    "    df_neg = defaultdict(lambda:0)\n",
    "    \n",
    "    for i in range(len(listOfTokenizedSentences)):\n",
    "        sent = listOfTokenizedSentences[i]\n",
    "        wordCounts = Counter(sent)\n",
    "        \n",
    "        for word in wordCounts:\n",
    "            tfs[word] += wordCounts[word]\n",
    "            dfs[word] += 1\n",
    "            \n",
    "            if listOfLabels[i] == 0:\n",
    "                df_pos[word] += 1\n",
    "            if listOfLabels[i] == 2:\n",
    "                df_neg[word] += 1\n",
    "                \n",
    "    return tfs,dfs,df_pos,df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfs,dfs,df_pos,df_neg = SOAC(list(train['clean_text']),list(train['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSOAC_BSWs(tfs,dfs,df_pos,df_neg,threshold):\n",
    "    bsws = []\n",
    "    for key in list(tfs.keys()):\n",
    "        if tfs[key] > threshold and df_pos[key] > df_neg[key]:\n",
    "            bsws.append(key)\n",
    "    return bsws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsws = getSOAC_BSWs(tfs,dfs,df_pos,df_neg,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testModelClassification('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1219, -0.7217,  2.5704]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModelClassification('kat is a woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "out,adj = testGraphClassification('kat is a woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8010, 0.1649, 0.0000, 0.0000, 0.1148],\n",
       "        [0.1649, 0.4794, 0.0536, 0.0850, 0.1577],\n",
       "        [0.0000, 0.0536, 0.4974, 0.1420, 0.1948],\n",
       "        [0.0000, 0.0850, 0.1420, 0.7267, 0.1325],\n",
       "        [0.1148, 0.1577, 0.1948, 0.1325, 0.3333]], device='cuda:1',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4846, -2.5655,  3.5461],\n",
       "        [ 0.7219, -2.7645,  7.6556],\n",
       "        [-1.0661,  7.6778, -2.7737],\n",
       "        [-6.1698, -2.0997,  1.7812],\n",
       "        [-8.7585, -0.9662, 14.4442]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelClassification('alice is a woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model(torch.tensor([word2idx[x] for x in ['can','you','throw','that','garbage','please']]).reshape(1,-1).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinned Bias Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinned_bias(listOfProbabilities, threshold_type, num_classes=3):\n",
    "    prob_hateful = listOfProbabilities\n",
    "#     print(listOfProbabilities)\n",
    "    \n",
    "    if threshold_type == 'mean':\n",
    "        pb = np.absolute(prob_hateful).sum() / len(listOfProbabilities)\n",
    "        \n",
    "    if threshold_type == 'sym':\n",
    "        num = np.array(prob_hateful) - 1/num_classes\n",
    "        pb = np.absolute(num).sum() / len(listOfProbabilities)\n",
    "        \n",
    "    if threshold_type == 'asym':\n",
    "        num = np.array(prob_hateful) - np.array([min(x,0.5) for x in prob_hateful])\n",
    "        pb = np.absolute(num).sum() / len(listOfProbabilities)\n",
    "    \n",
    "    return pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "hatefulProbsOfBSWs = [testGraphClassification(word)[0][0][0].item() for word in bsws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.387593045404979\n",
      "7.454259712071646\n",
      "1.8686438407216752\n"
     ]
    }
   ],
   "source": [
    "print(pinned_bias(hatefulProbsOfBSWs,'mean'))\n",
    "print(pinned_bias(hatefulProbsOfBSWs,'sym'))\n",
    "print(pinned_bias(hatefulProbsOfBSWs,'asym'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatefulProbsOfBSWs = [testModelClassification(word)[0][0].item() for word in bsws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887555593252182\n",
      "0.9103064400809152\n",
      "0.23139225499970573\n"
     ]
    }
   ],
   "source": [
    "print(pinned_bias(hatefulProbsOfBSWs,'mean'))\n",
    "print(pinned_bias(hatefulProbsOfBSWs,'sym'))\n",
    "print(pinned_bias(hatefulProbsOfBSWs,'asym'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "fakenews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
